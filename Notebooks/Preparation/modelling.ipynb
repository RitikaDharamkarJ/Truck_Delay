{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1074326\n",
      "Successfully connected to Hopsworks.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.59s) \n",
      "Downloaded feature group: final_merge_df (version 1)\n",
      "   truck_id    route_id            departure_date         estimated_arrival  \\\n",
      "0  21999423  R-65cfb635 2019-01-01 07:00:00+00:00 2019-01-01 12:00:00+00:00   \n",
      "1  25951646  R-05f9858a 2019-01-10 07:00:00+00:00 2019-01-11 01:00:00+00:00   \n",
      "2  31766919  R-08c77b90 2019-01-26 07:00:00+00:00 2019-01-27 08:00:00+00:00   \n",
      "3  33921946  R-5cc73966 2019-01-16 07:00:00+00:00 2019-01-16 08:00:00+00:00   \n",
      "4  13792231  R-71af6d34 2019-01-13 07:00:00+00:00 2019-01-13 18:00:00+00:00   \n",
      "\n",
      "   delay  route_avg_temp  route_avg_wind_speed  route_avg_precip  \\\n",
      "0      0       48.000000              8.000000               0.0   \n",
      "1      0       48.400000              6.200000               0.0   \n",
      "2      0       36.833333             15.166667               0.0   \n",
      "3      0       58.000000              7.000000               0.0   \n",
      "4      0       40.000000              6.000000               0.0   \n",
      "\n",
      "   route_avg_humidity  route_avg_visibility  ...  gender   age experience  \\\n",
      "0           58.500000                   5.0  ...    male  40.0        8.0   \n",
      "1           49.000000                   6.0  ...    male  39.0        4.0   \n",
      "2           56.333333                   6.0  ...    male  51.0       15.0   \n",
      "3           54.500000                   6.0  ...    male  45.0       16.0   \n",
      "4           84.333333                   6.0  ...    male  45.0        8.0   \n",
      "\n",
      "  driving_style ratings  vehicle_no  average_speed_mph  is_midnight  \\\n",
      "0  conservative     7.0  21999423.0              46.78            0   \n",
      "1  conservative     2.0  25951646.0              47.45            1   \n",
      "2  conservative     8.0  31766919.0              43.41            1   \n",
      "3  conservative     7.0  33921946.0              36.30            0   \n",
      "4     proactive     7.0  13792231.0              60.53            0   \n",
      "\n",
      "   unique_id                event_time  \n",
      "0      11750 2024-10-08 00:00:00+00:00  \n",
      "1      10226 2024-10-08 00:00:00+00:00  \n",
      "2       2921 2024-10-08 00:00:00+00:00  \n",
      "3         96 2024-10-08 00:00:00+00:00  \n",
      "4       4167 2024-10-08 00:00:00+00:00  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from hsfs.client.exceptions import RestAPIError\n",
    "\n",
    "try:\n",
    "    # Establish connection to Hopsworks\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=\"O4IOxWozstKu0BFQ.07C1tbvgVI5C4XNLbLrGH4PS4t0EqBYN00ex8318TNIkl82WwDi3Vh9MidMrCA83\"\n",
    "    )\n",
    "    print(\"Successfully connected to Hopsworks.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to Hopsworks.\")\n",
    "    print(e)\n",
    "    exit(1)  # Exit if the connection fails\n",
    "\n",
    "try:\n",
    "    # Access the Feature Store\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    # Retrieve the feature group by name and version\n",
    "    feature_group = fs.get_feature_group(\"final_merge_df\", version=1)\n",
    "\n",
    "    # Read the feature group as a DataFrame\n",
    "    df = feature_group.read()\n",
    "\n",
    "    # Print confirmation and the first few rows of the DataFrame\n",
    "    print(\"Downloaded feature group: final_merge_df (version 1)\")\n",
    "    print(df.head())\n",
    "\n",
    "except RestAPIError as e:\n",
    "    print(\"Error downloading feature group: final_merge_df (version 1)\")\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(\"An unexpected error occurred.\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truck_id                          0\n",
       "route_id                          0\n",
       "departure_date                    0\n",
       "estimated_arrival                 0\n",
       "delay                             0\n",
       "route_avg_temp                    0\n",
       "route_avg_wind_speed              0\n",
       "route_avg_precip                  0\n",
       "route_avg_humidity                0\n",
       "route_avg_visibility              0\n",
       "route_avg_pressure                0\n",
       "route_description                 0\n",
       "estimated_arrival_nearest_hour    0\n",
       "departure_date_nearest_hour       0\n",
       "origin_id                         0\n",
       "destination_id                    0\n",
       "distance                          0\n",
       "average_hours                     0\n",
       "temp_x                            0\n",
       "wind_speed_x                      0\n",
       "description_x                     0\n",
       "precip_x                          0\n",
       "humidity_x                        0\n",
       "visibility_x                      0\n",
       "pressure_x                        0\n",
       "temp_y                            0\n",
       "wind_speed_y                      0\n",
       "description_y                     0\n",
       "precip_y                          0\n",
       "humidity_y                        0\n",
       "visibility_y                      0\n",
       "pressure_y                        0\n",
       "avg_no_of_vehicles                0\n",
       "accident                          0\n",
       "truck_age                         0\n",
       "load_capacity_pounds              0\n",
       "mileage_mpg                       0\n",
       "fuel_type                         0\n",
       "driver_id                         0\n",
       "name                              0\n",
       "gender                            0\n",
       "age                               0\n",
       "experience                        0\n",
       "driving_style                     0\n",
       "ratings                           0\n",
       "vehicle_no                        0\n",
       "average_speed_mph                 0\n",
       "is_midnight                       0\n",
       "unique_id                         0\n",
       "event_time                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-01-01 07:00:00+0000', tz='UTC'),\n",
       " Timestamp('2019-02-13 06:00:00+0000', tz='UTC'))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge['estimated_arrival'].min(), final_merge['estimated_arrival'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training, validation, and test sets based on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['truck_id', 'route_id', 'departure_date', 'estimated_arrival', 'delay',\n",
       "       'route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip',\n",
       "       'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure',\n",
       "       'route_description', 'estimated_arrival_nearest_hour',\n",
       "       'departure_date_nearest_hour', 'origin_id', 'destination_id',\n",
       "       'distance', 'average_hours', 'temp_x', 'wind_speed_x', 'description_x',\n",
       "       'precip_x', 'humidity_x', 'visibility_x', 'pressure_x', 'temp_y',\n",
       "       'wind_speed_y', 'description_y', 'precip_y', 'humidity_y',\n",
       "       'visibility_y', 'pressure_y', 'avg_no_of_vehicles', 'accident',\n",
       "       'truck_age', 'load_capacity_pounds', 'mileage_mpg', 'fuel_type',\n",
       "       'driver_id', 'name', 'gender', 'age', 'experience', 'driving_style',\n",
       "       'ratings', 'vehicle_no', 'average_speed_mph', 'is_midnight',\n",
       "       'unique_id', 'event_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Column Names:\n",
      "Index(['truck_id', 'route_id', 'departure_date', 'estimated_arrival', 'delay',\n",
      "       'route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip',\n",
      "       'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure',\n",
      "       'route_description', 'estimated_arrival_nearest_hour',\n",
      "       'departure_date_nearest_hour', 'origin_id', 'destination_id',\n",
      "       'distance', 'average_hours', 'temp_origin', 'wind_speed_origin',\n",
      "       'description_origin', 'precip_origin', 'humidity_origin',\n",
      "       'visibility_origin', 'pressure_origin', 'temp_destination',\n",
      "       'wind_speed_destination', 'description_destination',\n",
      "       'precip_destination', 'humidity_destination', 'visibility_destination',\n",
      "       'pressure_destination', 'avg_no_of_vehicles', 'accident', 'truck_age',\n",
      "       'load_capacity_pounds', 'mileage_mpg', 'fuel_type', 'driver_id', 'name',\n",
      "       'gender', 'age', 'experience', 'driving_style', 'ratings', 'vehicle_no',\n",
      "       'average_speed_mph', 'is_midnight', 'unique_id', 'event_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Ensure the suffixes '_x' and '_y' are replaced with '_origin' and '_destination'\n",
    "final_merge.columns = final_merge.columns.str.replace('_x$', '_origin', regex=True)\n",
    "final_merge.columns = final_merge.columns.str.replace('_y$', '_destination', regex=True)\n",
    "\n",
    "# Optional: Verify the changes\n",
    "print(\"Updated Column Names:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updated Code to Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Column Names:\n",
      "Index(['truck_id', 'route_id', 'departure_date', 'estimated_arrival', 'delay',\n",
      "       'route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip',\n",
      "       'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure',\n",
      "       'route_description', 'estimated_arrival_nearest_hour',\n",
      "       'departure_date_nearest_hour', 'origin_id', 'destination_id',\n",
      "       'distance', 'average_hours', 'temp_origin', 'wind_speed_origin',\n",
      "       'origin_description', 'precip_origin', 'humidity_origin',\n",
      "       'visibility_origin', 'pressure_origin', 'temp_destination',\n",
      "       'wind_speed_destination', 'destination_description',\n",
      "       'precip_destination', 'humidity_destination', 'visibility_destination',\n",
      "       'pressure_destination', 'avg_no_of_vehicles', 'accident', 'truck_age',\n",
      "       'load_capacity_pounds', 'mileage_mpg', 'fuel_type', 'driver_id', 'name',\n",
      "       'gender', 'age', 'experience', 'driving_style', 'ratings', 'vehicle_no',\n",
      "       'average_speed_mph', 'is_midnight', 'unique_id', 'event_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Dictionary mapping actual column names to expected column names\n",
    "rename_mapping = {\n",
    "    'origin_temp': 'temp_origin',\n",
    "    'origin_wind_speed': 'wind_speed_origin',\n",
    "    'origin_precip': 'precip_origin',\n",
    "    'origin_humidity': 'humidity_origin',\n",
    "    'origin_visibility': 'visibility_origin',\n",
    "    'origin_pressure': 'pressure_origin',\n",
    "    'destination_temp': 'temp_destination',\n",
    "    'destination_wind_speed': 'wind_speed_destination',\n",
    "    'destination_precip': 'precip_destination',\n",
    "    'destination_humidity': 'humidity_destination',\n",
    "    'destination_visibility': 'visibility_destination',\n",
    "    'destination_pressure': 'pressure_destination',\n",
    "    'description_origin': 'origin_description',\n",
    "    'description_destination': 'destination_description'\n",
    "}\n",
    "\n",
    "# Apply the renaming to the DataFrame\n",
    "final_merge = final_merge.rename(columns=rename_mapping)\n",
    "\n",
    "# Optional: Verify the changes\n",
    "print(\"Updated Column Names:\")\n",
    "print(final_merge.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts_cols=['route_avg_temp', 'route_avg_wind_speed',\n",
    "              'route_avg_precip', 'route_avg_humidity', 'route_avg_visibility',\n",
    "              'route_avg_pressure', 'distance', 'average_hours',\n",
    "              'origin_temp', 'origin_wind_speed', 'origin_precip', 'origin_humidity',\n",
    "              'origin_visibility', 'origin_pressure',\n",
    "              'destination_temp','destination_wind_speed','destination_precip',\n",
    "              'destination_humidity', 'destination_visibility','destination_pressure',\n",
    "               'avg_no_of_vehicles', 'truck_age','load_capacity_pounds', 'mileage_mpg',\n",
    "               'age', 'experience','average_speed_mph']\n",
    "\n",
    "cat_cols=['route_description',\n",
    "              'origin_description', 'destination_description',\n",
    "               'accident', 'fuel_type',\n",
    "              'gender', 'driving_style', 'ratings','is_midnight']\n",
    "\n",
    "target=['delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-01-01 07:00:00+0000', tz='UTC'),\n",
       " Timestamp('2019-02-13 06:00:00+0000', tz='UTC'))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the date range\n",
    "final_merge['estimated_arrival'].min(), final_merge['estimated_arrival'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training, validation, and test sets based on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Ensure 'estimated_arrival' is timezone-aware (UTC)\n",
    "final_merge['estimated_arrival'] = final_merge['estimated_arrival'].dt.tz_convert('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   truck_id    route_id            departure_date         estimated_arrival  \\\n",
      "0  21999423  R-65cfb635 2019-01-01 07:00:00+00:00 2019-01-01 12:00:00+00:00   \n",
      "1  25951646  R-05f9858a 2019-01-10 07:00:00+00:00 2019-01-11 01:00:00+00:00   \n",
      "2  31766919  R-08c77b90 2019-01-26 07:00:00+00:00 2019-01-27 08:00:00+00:00   \n",
      "3  33921946  R-5cc73966 2019-01-16 07:00:00+00:00 2019-01-16 08:00:00+00:00   \n",
      "4  13792231  R-71af6d34 2019-01-13 07:00:00+00:00 2019-01-13 18:00:00+00:00   \n",
      "\n",
      "   delay  route_avg_temp  route_avg_wind_speed  route_avg_precip  \\\n",
      "0      0       48.000000              8.000000               0.0   \n",
      "1      0       48.400000              6.200000               0.0   \n",
      "2      0       36.833333             15.166667               0.0   \n",
      "3      0       58.000000              7.000000               0.0   \n",
      "4      0       40.000000              6.000000               0.0   \n",
      "\n",
      "   route_avg_humidity  route_avg_visibility  ...  gender   age experience  \\\n",
      "0           58.500000                   5.0  ...    male  40.0        8.0   \n",
      "1           49.000000                   6.0  ...    male  39.0        4.0   \n",
      "2           56.333333                   6.0  ...    male  51.0       15.0   \n",
      "3           54.500000                   6.0  ...    male  45.0       16.0   \n",
      "4           84.333333                   6.0  ...    male  45.0        8.0   \n",
      "\n",
      "  driving_style ratings  vehicle_no  average_speed_mph  is_midnight  \\\n",
      "0  conservative     7.0  21999423.0              46.78            0   \n",
      "1  conservative     2.0  25951646.0              47.45            1   \n",
      "2  conservative     8.0  31766919.0              43.41            1   \n",
      "3  conservative     7.0  33921946.0              36.30            0   \n",
      "4     proactive     7.0  13792231.0              60.53            0   \n",
      "\n",
      "   unique_id                event_time  \n",
      "0      11750 2024-10-08 00:00:00+00:00  \n",
      "1      10226 2024-10-08 00:00:00+00:00  \n",
      "2       2921 2024-10-08 00:00:00+00:00  \n",
      "3         96 2024-10-08 00:00:00+00:00  \n",
      "4       4167 2024-10-08 00:00:00+00:00  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a UTC-aware comparison timestamp\n",
    "comparison_date = pd.to_datetime('2019-01-30', utc=True)\n",
    "\n",
    "# Filter the DataFrame based on the comparison\n",
    "train_df = final_merge[final_merge['estimated_arrival'] <= comparison_date]\n",
    "\n",
    "# Optional: Display the result to verify\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UTC-aware comparison timestamps\n",
    "start_date = pd.to_datetime('2019-01-30', utc=True)\n",
    "end_date = pd.to_datetime('2019-02-07', utc=True)\n",
    "\n",
    "# Filter the DataFrame based on the date range\n",
    "validation_df = final_merge[\n",
    "    (final_merge['estimated_arrival'] > start_date) & \n",
    "    (final_merge['estimated_arrival'] <= end_date)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a UTC-aware timestamp for comparison\n",
    "comparison_date_1 = pd.to_datetime('2019-02-07', utc=True)\n",
    "\n",
    "# Filter the DataFrame to get the test set\n",
    "test_df = final_merge[final_merge['estimated_arrival'] > comparison_date_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7296, 24)\n"
     ]
    }
   ],
   "source": [
    "# Ensure that only available columns are used to avoid KeyError\n",
    "available_cts_cols = [col for col in cts_cols if col in train_df.columns]\n",
    "available_cat_cols = [col for col in cat_cols if col in train_df.columns]\n",
    "\n",
    "# Combine continuous and categorical columns that are present\n",
    "selected_columns = available_cts_cols + available_cat_cols\n",
    "\n",
    "# Ensure there are columns to use\n",
    "if not selected_columns:\n",
    "    print(\"No valid columns found for training.\")\n",
    "else:\n",
    "    # Select the available columns from the DataFrame\n",
    "    X_train = train_df[selected_columns]\n",
    "    y_train = train_df['delay']  # Assuming 'delay' is the target variable\n",
    "\n",
    "    # Optional: Print the shape to confirm selection\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_df['delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid shape: (1949, 24)\n",
      "y_valid shape: (1949,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure only the columns that are present in validation_df are selected\n",
    "available_cts_cols = [col for col in cts_cols if col in validation_df.columns]\n",
    "available_cat_cols = [col for col in cat_cols if col in validation_df.columns]\n",
    "\n",
    "# Combine available continuous and categorical columns\n",
    "selected_columns = available_cts_cols + available_cat_cols\n",
    "\n",
    "# Check if any valid columns are available\n",
    "if not selected_columns:\n",
    "    raise ValueError(\"No valid columns found in validation_df for feature selection.\")\n",
    "\n",
    "# Select the columns from validation_df\n",
    "X_valid = validation_df[selected_columns]\n",
    "\n",
    "# Select the target variable (assuming 'delay' is the target)\n",
    "y_valid = validation_df['delay']\n",
    "\n",
    "# Print the shape to confirm\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = validation_df['delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (1227, 24)\n",
      "y_test shape: (1227,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure only available columns are selected from test_df\n",
    "available_cts_cols = [col for col in cts_cols if col in test_df.columns]\n",
    "available_cat_cols = [col for col in cat_cols if col in test_df.columns]\n",
    "\n",
    "# Combine available continuous and categorical columns\n",
    "selected_columns = available_cts_cols + available_cat_cols\n",
    "\n",
    "# Check if any valid columns are available\n",
    "if not selected_columns:\n",
    "    raise ValueError(\"No valid columns found in test_df for feature selection.\")\n",
    "\n",
    "# Select the available columns for X_test\n",
    "X_test = test_df[selected_columns]\n",
    "\n",
    "# Select the target variable (assuming 'delay' is the target)\n",
    "y_test = test_df['delay']\n",
    "\n",
    "# Optional: Print the shape to confirm\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_df['delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the columns to be one-hot encoded\n",
    "encode_columns = ['route_description', 'origin_description', 'destination_description', 'fuel_type', 'gender', 'driving_style']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the OneHotEncoder with updated parameter\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore', sparse_output=False)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Fit the encoder on the training data\n",
    "encoder.fit(X_train[encode_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating names for the new one-hot encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = list(encoder.get_feature_names_out(encode_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transforming the training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-17 00:05:27,395 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,397 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,398 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,401 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,403 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,407 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,409 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,412 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,415 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,417 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,418 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,420 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,422 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,425 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,427 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,430 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,432 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,433 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,436 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,438 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,439 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,440 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,442 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,444 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,446 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,463 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,464 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,466 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,468 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,470 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,472 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,474 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,476 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,478 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,480 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,481 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,484 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,485 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,488 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,490 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,492 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,494 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train[encoded_features] = encoder.transform(X_train[encode_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-17 00:05:27,515 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,517 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,518 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,521 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,523 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,525 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,527 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,528 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,529 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,532 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,534 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,536 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,538 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,540 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,541 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,543 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,544 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,545 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,547 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,549 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,552 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,554 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,556 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,557 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,559 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,576 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,577 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,579 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,581 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,584 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,585 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,587 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,589 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,590 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,592 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,593 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,595 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,597 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,599 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,601 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,603 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,604 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_valid[encoded_features] = encoder.transform(X_valid[encode_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-17 00:05:27,623 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,624 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,627 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,628 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,630 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,632 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,635 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,637 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,638 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,639 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,641 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,642 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,645 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,646 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,648 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,649 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,651 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,654 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,659 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,661 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,663 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,665 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,668 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,670 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,673 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-17 00:05:27,694 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,697 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,699 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,701 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,704 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,707 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,710 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,713 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,714 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,716 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,718 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,721 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,722 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,723 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,725 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,726 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-17 00:05:27,728 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test[encoded_features] = encoder.transform(X_test[encode_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping the original categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(encode_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X_valid.drop(encode_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(encode_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after scaling: (7296, 132)\n",
      "X_valid shape after scaling: (1949, 132)\n",
      "X_test shape after scaling: (1227, 132)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Step 2: Identify numerical columns to scale\n",
    "# Ensure we only scale the encoded categorical columns and other numerical columns if needed.\n",
    "columns_to_scale = X_train.columns  # Adjust if you only want specific columns\n",
    "\n",
    "# Step 3: Fit the scaler on X_train and transform X_train, X_valid, and X_test\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train[columns_to_scale]), \n",
    "                              columns=columns_to_scale, index=X_train.index)\n",
    "\n",
    "X_valid_scaled = pd.DataFrame(scaler.transform(X_valid[columns_to_scale]), \n",
    "                              columns=columns_to_scale, index=X_valid.index)\n",
    "\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test[columns_to_scale]), \n",
    "                             columns=columns_to_scale, index=X_test.index)\n",
    "\n",
    "# Optional: Verify the shapes\n",
    "print(f\"X_train shape after scaling: {X_train_scaled.shape}\")\n",
    "print(f\"X_valid shape after scaling: {X_valid_scaled.shape}\")\n",
    "print(f\"X_test shape after scaling: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in c:\\truck_delay_classification\\.venv\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\truck_delay_classification\\.venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: xgboost in c:\\truck_delay_classification\\.venv\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: mlflow-skinny==2.17.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (2.17.0)\n",
      "Requirement already satisfied: Flask<4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (3.0.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (1.13.3)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (3.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (2.1.4)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (17.0.0)\n",
      "Requirement already satisfied: scipy<2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (1.4.48)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: waitress<4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (0.34.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (8.4.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n",
      "Requirement already satisfied: packaging<25 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (5.28.2)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: Mako in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (306)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Flask<4->mlflow) (3.0.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Flask<4->mlflow) (1.8.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from graphene<4->mlflow) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.17.0->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.35.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.48b0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "2024-10-17 00:11:32,348 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/17 00:11:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Accuracy: 0.7493150684931507, F1 Score: 0.7228845969625737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1020\n",
      "           1       0.66      0.35      0.46       440\n",
      "\n",
      "    accuracy                           0.75      1460\n",
      "   macro avg       0.71      0.64      0.65      1460\n",
      "weighted avg       0.73      0.75      0.72      1460\n",
      "\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "2024-10-17 00:11:51,897 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/17 00:11:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.7856164383561643, F1 Score: 0.7665956295952192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      1020\n",
      "           1       0.75      0.44      0.55       440\n",
      "\n",
      "    accuracy                           0.79      1460\n",
      "   macro avg       0.77      0.69      0.71      1460\n",
      "weighted avg       0.78      0.79      0.77      1460\n",
      "\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "2024-10-17 00:12:04,615 WARNING: UserWarning: [00:12:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "\n",
      "2024-10-17 00:12:04,794 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/17 00:12:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50}\n",
      "Accuracy: 0.7849315068493151, F1 Score: 0.765700426854712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      1020\n",
      "           1       0.74      0.44      0.55       440\n",
      "\n",
      "    accuracy                           0.78      1460\n",
      "   macro avg       0.77      0.69      0.70      1460\n",
      "weighted avg       0.78      0.78      0.77      1460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Define X_train, X_valid, y_train, y_valid (use your existing datasets)\n",
    "X = X_train_scaled  # Assuming scaled features\n",
    "y = y_train\n",
    "\n",
    "# Split the data further for GridSearch if needed\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"ML Models with Hyperparameter Tuning\")\n",
    "\n",
    "# Define a function to train and log models with MLflow\n",
    "def train_and_evaluate_model(model, param_grid, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "        # Get the best model from GridSearch\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_pred = best_model.predict(X_val_split)\n",
    "\n",
    "        # Evaluate performance\n",
    "        acc = accuracy_score(y_val_split, y_pred)\n",
    "        f1 = f1_score(y_val_split, y_pred, average='weighted')\n",
    "\n",
    "        # Log parameters, metrics, and model\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\"accuracy\": acc, \"f1_score\": f1})\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Best Parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Accuracy: {acc}, F1 Score: {f1}\")\n",
    "        print(classification_report(y_val_split, y_pred))\n",
    "\n",
    "# Hyperparameter grids for each model\n",
    "logreg_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10]\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "train_and_evaluate_model(LogisticRegression(), logreg_params, \"Logistic Regression\")\n",
    "train_and_evaluate_model(RandomForestClassifier(), rf_params, \"Random Forest\")\n",
    "train_and_evaluate_model(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "2024-10-16 22:47:17,063 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/16 22:47:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Validation Accuracy: 0.7493, F1 Score: 0.7229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1020\n",
      "           1       0.66      0.35      0.46       440\n",
      "\n",
      "    accuracy                           0.75      1460\n",
      "   macro avg       0.71      0.64      0.65      1460\n",
      "weighted avg       0.73      0.75      0.72      1460\n",
      "\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "2024-10-16 22:47:23,951 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/16 22:47:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Validation Accuracy: 0.7747, F1 Score: 0.7562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85      1020\n",
      "           1       0.71      0.43      0.54       440\n",
      "\n",
      "    accuracy                           0.77      1460\n",
      "   macro avg       0.75      0.68      0.69      1460\n",
      "weighted avg       0.76      0.77      0.76      1460\n",
      "\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "2024-10-16 22:47:29,212 WARNING: UserWarning: [22:47:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "\n",
      "2024-10-16 22:47:29,386 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/16 22:47:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50}\n",
      "Validation Accuracy: 0.7849, F1 Score: 0.7657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      1020\n",
      "           1       0.74      0.44      0.55       440\n",
      "\n",
      "    accuracy                           0.78      1460\n",
      "   macro avg       0.77      0.69      0.70      1460\n",
      "weighted avg       0.78      0.78      0.77      1460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy for the validation dataset\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Function to train and evaluate the model, including validation accuracy\n",
    "def train_and_evaluate_model(model, param_grid, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "        # Get the best model from GridSearch\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = best_model.predict(X_val_split)\n",
    "\n",
    "        # Calculate validation accuracy and F1 score\n",
    "        val_accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "        val_f1 = f1_score(y_val_split, y_val_pred, average='weighted')\n",
    "\n",
    "        # Log parameters, metrics, and model with MLflow\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\"val_accuracy\": val_accuracy, \"val_f1_score\": val_f1})\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n",
    "\n",
    "        # Print the evaluation results\n",
    "        print(f\"Best Parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "        print(classification_report(y_val_split, y_val_pred))\n",
    "\n",
    "# Example hyperparameter grids\n",
    "logreg_params = {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear'], 'max_iter': [100, 200]}\n",
    "rf_params = {'n_estimators': [50, 100], 'max_depth': [None, 10], 'min_samples_split': [2, 5]}\n",
    "xgb_params = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 6]}\n",
    "\n",
    "# Train models with the new function\n",
    "train_and_evaluate_model(LogisticRegression(), logreg_params, \"Logistic Regression\")\n",
    "train_and_evaluate_model(RandomForestClassifier(), rf_params, \"Random Forest\")\n",
    "train_and_evaluate_model(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "2024-10-18 13:41:30,174 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 13:41:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Training Accuracy: 0.7629, F1 Score: 0.7368, Precision: 0.7562, Recall: 0.7629\n",
      "Training classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      5040\n",
      "           1       0.73      0.38      0.49      2256\n",
      "\n",
      "    accuracy                           0.76      7296\n",
      "   macro avg       0.75      0.66      0.67      7296\n",
      "weighted avg       0.76      0.76      0.74      7296\n",
      "\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "2024-10-18 13:41:55,805 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 13:41:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 150}\n",
      "Training Accuracy: 0.8675, F1 Score: 0.8559, Precision: 0.8856, Recall: 0.8675\n",
      "Training classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      5040\n",
      "           1       0.98      0.58      0.73      2256\n",
      "\n",
      "    accuracy                           0.87      7296\n",
      "   macro avg       0.91      0.79      0.82      7296\n",
      "weighted avg       0.89      0.87      0.86      7296\n",
      "\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "2024-10-18 13:42:10,275 WARNING: UserWarning: [13:42:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "\n",
      "2024-10-18 13:42:10,495 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 13:42:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50}\n",
      "Training Accuracy: 0.8136, F1 Score: 0.7967, Precision: 0.8184, Recall: 0.8136\n",
      "Training classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      5040\n",
      "           1       0.84      0.49      0.62      2256\n",
      "\n",
      "    accuracy                           0.81      7296\n",
      "   macro avg       0.83      0.72      0.75      7296\n",
      "weighted avg       0.82      0.81      0.80      7296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training dataset\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Define X_train, y_train (use your existing datasets)\n",
    "X_train_split = X_train_scaled  # Assuming scaled features\n",
    "y_train_split = y_train  # Assuming labels\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"ML Models with Hyperparameter Tuning\")\n",
    "\n",
    "# Define a function to train and log models with MLflow\n",
    "def train_and_evaluate_on_train(model, param_grid, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "        # Get the best model from GridSearch\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluate on the training dataset\n",
    "        y_train_pred = best_model.predict(X_train_split)\n",
    "        train_acc = accuracy_score(y_train_split, y_train_pred)\n",
    "        train_f1 = f1_score(y_train_split, y_train_pred, average='weighted')\n",
    "        train_precision = precision_score(y_train_split, y_train_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train_split, y_train_pred, average='weighted')\n",
    "\n",
    "        # Log parameters, metrics, and model\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\"train_accuracy\": train_acc, \"train_f1_score\": train_f1,\n",
    "                            \"train_precision\": train_precision, \"train_recall\": train_recall})\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n",
    "\n",
    "        # Print the evaluation results for training\n",
    "        print(f\"Best Parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Training Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}\")\n",
    "        print(\"Training classification report:\")\n",
    "        print(classification_report(y_train_split, y_train_pred))\n",
    "\n",
    "# Hyperparameter grids for each model\n",
    "logreg_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 175, 150],\n",
    "    'max_depth': [None, 10, 15],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 3]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10]\n",
    "}\n",
    "\n",
    "# Train and evaluate models on training data only\n",
    "train_and_evaluate_on_train(LogisticRegression(), logreg_params, \"Logistic Regression\")\n",
    "train_and_evaluate_on_train(RandomForestClassifier(), rf_params, \"Random Forest\")\n",
    "train_and_evaluate_on_train(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1107632925.py, line 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[245], line 69\u001b[1;36m\u001b[0m\n\u001b[1;33m    evaluate_on_test(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params,scoring='accuracy', cv=5,verbose=2,n_jobs=-1, \"XGBoost\")\u001b[0m\n\u001b[1;37m                                                                                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "#Testing dataset\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Define X_test and y_test (use your existing testing datasets)\n",
    "X_test_split = X_test_scaled  # Assuming scaled test features\n",
    "y_test_split = y_test  # Assuming test labels\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"ML Models with Hyperparameter Tuning\")\n",
    "\n",
    "# Define a function to evaluate models on testing data with MLflow\n",
    "def evaluate_on_test(model, param_grid, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train_split, y_train_split)  # Train on the training set\n",
    "\n",
    "        # Get the best model from GridSearch\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluate on the testing dataset\n",
    "        y_test_pred = best_model.predict(X_test_split)\n",
    "        test_acc = accuracy_score(y_test_split, y_test_pred)\n",
    "        test_f1 = f1_score(y_test_split, y_test_pred, average='weighted')\n",
    "        test_precision = precision_score(y_test_split, y_test_pred, average='weighted')\n",
    "        test_recall = recall_score(y_test_split, y_test_pred, average='weighted')\n",
    "\n",
    "        # Log parameters, metrics, and model\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\"test_accuracy\": test_acc, \"test_f1_score\": test_f1,\n",
    "                            \"test_precision\": test_precision, \"test_recall\": test_recall})\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n",
    "\n",
    "        # Print the evaluation results for testing\n",
    "        print(f\"Best Parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}, F1 Score: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\n",
    "        print(\"Test classification report:\")\n",
    "        print(classification_report(y_test_split, y_test_pred))\n",
    "\n",
    "# Hyperparameter grids for each model\n",
    "logreg_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 150, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 150, 200, 300, 500],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9, 12]\n",
    "}\n",
    "\n",
    "# Train models on training set and evaluate on testing data\n",
    "evaluate_on_test(LogisticRegression(), logreg_params, \"Logistic Regression\")\n",
    "evaluate_on_test(RandomForestClassifier(), rf_params, \"Random Forest\")\n",
    "evaluate_on_test(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params,\"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "2024-10-18 13:56:36,180 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 13:56:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Logistic_Regression_model.pkl\n",
      "Best Parameters for Logistic_Regression: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Training Accuracy: 0.7629, F1 Score: 0.7368, Precision: 0.7562, Recall: 0.7629\n",
      "Training classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      5040\n",
      "           1       0.73      0.38      0.49      2256\n",
      "\n",
      "    accuracy                           0.76      7296\n",
      "   macro avg       0.75      0.66      0.67      7296\n",
      "weighted avg       0.76      0.76      0.74      7296\n",
      "\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "2024-10-18 13:56:59,721 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 13:57:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Random_Forest_model.pkl\n",
      "Best Parameters for Random_Forest: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 150}\n",
      "Training Accuracy: 0.8635, F1 Score: 0.8512, Precision: 0.8823, Recall: 0.8635\n",
      "Training classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      5040\n",
      "           1       0.98      0.57      0.72      2256\n",
      "\n",
      "    accuracy                           0.86      7296\n",
      "   macro avg       0.91      0.78      0.82      7296\n",
      "weighted avg       0.88      0.86      0.85      7296\n",
      "\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "2024-10-18 13:57:14,441 WARNING: UserWarning: [13:57:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "\n",
      "2024-10-18 13:57:14,671 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 13:57:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as XGBoost_model.pkl\n",
      "Best Parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50}\n",
      "Training Accuracy: 0.8136, F1 Score: 0.7967, Precision: 0.8184, Recall: 0.8136\n",
      "Training classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      5040\n",
      "           1       0.84      0.49      0.62      2256\n",
      "\n",
      "    accuracy                           0.81      7296\n",
      "   macro avg       0.83      0.72      0.75      7296\n",
      "weighted avg       0.82      0.81      0.80      7296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Define X_train, y_train (use your existing datasets)\n",
    "X_train_split = X_train_scaled  # Assuming scaled features\n",
    "y_train_split = y_train  # Assuming labels\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"ML Models with Hyperparameter Tuning\")\n",
    "\n",
    "# Define a function to train, evaluate, and save models as pickle files\n",
    "def train_evaluate_save_as_pickle(model, param_grid, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "        # Get the best model from GridSearch\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluate on the training dataset\n",
    "        y_train_pred = best_model.predict(X_train_split)\n",
    "        train_acc = accuracy_score(y_train_split, y_train_pred)\n",
    "        train_f1 = f1_score(y_train_split, y_train_pred, average='weighted')\n",
    "        train_precision = precision_score(y_train_split, y_train_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train_split, y_train_pred, average='weighted')\n",
    "\n",
    "        # Log parameters, metrics, and model with MLflow\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\"train_accuracy\": train_acc, \"train_f1_score\": train_f1,\n",
    "                            \"train_precision\": train_precision, \"train_recall\": train_recall})\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n",
    "\n",
    "        # Save model as a pickle file\n",
    "        with open(f\"{model_name}_model.pkl\", 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        print(f\"Model saved as {model_name}_model.pkl\")\n",
    "\n",
    "        # Print the evaluation results for training\n",
    "        print(f\"Best Parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Training Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}\")\n",
    "        print(\"Training classification report:\")\n",
    "        print(classification_report(y_train_split, y_train_pred))\n",
    "\n",
    "# Hyperparameter grids for each model\n",
    "logreg_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 175, 150],\n",
    "    'max_depth': [None, 10, 15],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 3]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10]\n",
    "}\n",
    "\n",
    "# Train, evaluate, and save models on training data\n",
    "train_evaluate_save_as_pickle(LogisticRegression(), logreg_params, \"Logistic_Regression\")\n",
    "train_evaluate_save_as_pickle(RandomForestClassifier(), rf_params, \"Random_Forest\")\n",
    "train_evaluate_save_as_pickle(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the XGBoost model from the pickle file\n",
    "with open(\"XGBoost_model.pkl\", 'rb') as f:\n",
    "    best_xgboost_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hopsworks in c:\\truck_delay_classification\\.venv\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: hsfs<3.8.0,>=3.7.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.7.7)\n",
      "Requirement already satisfied: hsml<3.8.0,>=3.7.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hopsworks) (3.7.1)\n",
      "Requirement already satisfied: pyhumps==1.6.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hopsworks) (1.6.1)\n",
      "Requirement already satisfied: requests in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hopsworks) (2.32.3)\n",
      "Requirement already satisfied: furl in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hopsworks) (2.1.3)\n",
      "Requirement already satisfied: boto3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hopsworks) (1.35.22)\n",
      "Requirement already satisfied: pyjks in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hopsworks) (20.0.0)\n",
      "Requirement already satisfied: mock in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hopsworks) (5.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hopsworks) (4.66.5)\n",
      "Requirement already satisfied: pandas<2.2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.1.4)\n",
      "Requirement already satisfied: numpy<2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.26.4)\n",
      "Requirement already satisfied: avro==1.11.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.11.3)\n",
      "Requirement already satisfied: sqlalchemy<=1.4.48 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.4.48)\n",
      "Requirement already satisfied: PyMySQL[rsa] in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.1.1)\n",
      "Requirement already satisfied: great-expectations==0.18.12 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.18.12)\n",
      "Requirement already satisfied: tzlocal in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.2)\n",
      "Requirement already satisfied: fsspec in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2024.9.0)\n",
      "Requirement already satisfied: retrying in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.4)\n",
      "Requirement already satisfied: aiomysql in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.0)\n",
      "Requirement already satisfied: opensearch-py<=2.4.2,>=1.1.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.4.2)\n",
      "Requirement already satisfied: altair<5.0.0,>=4.2.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.2.2)\n",
      "Requirement already satisfied: Click>=7.1.2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (8.1.7)\n",
      "Requirement already satisfied: colorama>=0.4.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.4.6)\n",
      "Requirement already satisfied: cryptography>=3.2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (43.0.1)\n",
      "Requirement already satisfied: Ipython>=7.16.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (8.27.0)\n",
      "Requirement already satisfied: ipywidgets>=7.5.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (8.1.5)\n",
      "Requirement already satisfied: jinja2>=2.10 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.1.4)\n",
      "Requirement already satisfied: jsonpatch>=1.22 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.33)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.23.0)\n",
      "Requirement already satisfied: makefun<2,>=1.7.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.15.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.7.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.22.0)\n",
      "Requirement already satisfied: mistune>=0.8.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.0.2)\n",
      "Requirement already satisfied: nbformat>=5.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.10.4)\n",
      "Requirement already satisfied: notebook>=6.4.10 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (7.2.2)\n",
      "Requirement already satisfied: packaging in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (24.1)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.9.2)\n",
      "Requirement already satisfied: pyparsing>=2.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2021.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2024.2)\n",
      "Requirement already satisfied: ruamel.yaml<0.17.18,>=0.16 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.17.17)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.2.3)\n",
      "Requirement already satisfied: pyhopshive[thrift] in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.6.4.1.dev0)\n",
      "Requirement already satisfied: pyarrow>=10.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (17.0.0)\n",
      "Requirement already satisfied: confluent-kafka<=2.3.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.3.0)\n",
      "Requirement already satisfied: fastavro<=1.8.4,>=1.4.11 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from requests->hopsworks) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from requests->hopsworks) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from requests->hopsworks) (2024.8.30)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.22 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from boto3->hopsworks) (1.35.22)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from boto3->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from boto3->hopsworks) (0.10.2)\n",
      "Requirement already satisfied: six>=1.8.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from furl->hopsworks) (1.16.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from furl->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: javaobj-py3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pyjks->hopsworks) (0.4.4)\n",
      "Requirement already satisfied: pyasn1>=0.3.5 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pyjks->hopsworks) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pyjks->hopsworks) (0.4.1)\n",
      "Requirement already satisfied: pycryptodomex in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pyjks->hopsworks) (3.20.0)\n",
      "Requirement already satisfied: twofish in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pyjks->hopsworks) (0.3.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pandas<2.2.0->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2024.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from sqlalchemy<=1.4.48->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.1.0)\n",
      "Requirement already satisfied: future in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pyhopshive[thrift]; extra == \"python\"->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.0.0)\n",
      "Requirement already satisfied: thrift>=0.10.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pyhopshive[thrift]; extra == \"python\"->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.20.0)\n",
      "Requirement already satisfied: entrypoints in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from altair<5.0.0,>=4.2.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.4)\n",
      "Requirement already satisfied: toolz in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from altair<5.0.0,>=4.2.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from cryptography>=3.2->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.17.1)\n",
      "Requirement already satisfied: decorator in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from ipywidgets>=7.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from ipywidgets>=7.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from ipywidgets>=7.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.0.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jinja2>=2.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonpatch>=1.22->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonschema>=2.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonschema>=2.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonschema>=2.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonschema>=2.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.20.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbformat>=5.0->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.20.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbformat>=5.0->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.7.2)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.2.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pydantic>=1.9.2->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from pydantic>=1.9.2->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.23.4)\n",
      "Requirement already satisfied: pycparser in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=3.2->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jedi>=0.16->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.0->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.0->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (306)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.5.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (7.16.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.20.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.0.13)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (26.2.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.27.2)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.29.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (75.1.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.9.25)\n",
      "Requirement already satisfied: wcwidth in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (21.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.14.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.8.5)\n",
      "Requirement already satisfied: nest-asyncio in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.0.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.3.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.5.1)\n",
      "Requirement already satisfied: fqdn in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (20.11.0)\n",
      "Requirement already satisfied: uri-template in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (24.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.6)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\truck_delay_classification\\.venv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.9.0.20240906)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1074326\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcea4f9887b4311b7db6d028ba57bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61438f329f4d4c76a4aff24ff9efd687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/174184 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9084a1564a7346ada88d0060b59cfd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/2847 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1074326/models/XGBoost_Model/1\n",
      "Model 'XGBoost_Model' successfully saved to Hopsworks Model Registry.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Connect to your Hopsworks project\n",
    "project = hopsworks.login(\n",
    "        api_key_value=\"O4IOxWozstKu0BFQ.07C1tbvgVI5C4XNLbLrGH4PS4t0EqBYN00ex8318TNIkl82WwDi3Vh9MidMrCA83\"\n",
    "    )\n",
    "\n",
    "# Get the Model Registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Define model metadata and metrics (for example, based on your evaluation)\n",
    "metrics = {\n",
    "    \"accuracy\": 0.8136,\n",
    "    \"f1_score\": 0.7967,\n",
    "    \"precision\": 0.8184,\n",
    "    \"recall\": 0.8136\n",
    "}\n",
    "\n",
    "# Directory to save the model locally (for later upload to Hopsworks)\n",
    "model_dir = \"xgboost_model_directory\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save the XGBoost model locally using joblib\n",
    "joblib.dump(best_xgboost_model, f\"{model_dir}/xgboost_model.pkl\")\n",
    "\n",
    "# Upload the model to Hopsworks Model Registry\n",
    "model_meta = mr.python.create_model(\n",
    "    name=\"XGBoost_Model\",\n",
    "    description=\"Best XGBoost model trained with hyperparameter tuning\",\n",
    "    metrics=metrics,  # Dictionary of evaluation metrics like accuracy, f1_score\n",
    "    input_example=X_train_split[0:1]  # Optional: Example of input data\n",
    ")\n",
    "\n",
    "# Upload the actual model directory to the model registry\n",
    "model_meta.save(f\"{model_dir}/xgboost_model.pkl\")\n",
    "\n",
    "print(f\"Model 'XGBoost_Model' successfully saved to Hopsworks Model Registry.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
